{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b8d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6973f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\train.parquet')\n",
    "oos = pd.read_parquet(r'C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\oos.parquet')\n",
    "oot = pd.read_parquet(r'C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\oot.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a9364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C_GIOITINH', 'TTHONNHAN', 'NHANVIENBIDV', 'BASE_AUM', 'TUOI', 'INCOME',\n",
       "       'CBAL', 'AFLIMT_AVG', 'LTV', 'N_AVG_DEPOSIT_12M', 'FLAG_SALARY_ACC',\n",
       "       'FLAG_DEPOSIT', 'UTILIZATION_RATE', 'CNT_CREDIT_CARDS',\n",
       "       'AMT_CASH_ADVANCE_12M', 'PCT_PAYMENT_TO_BALANCE', 'CNT_MIN_PAY_6M',\n",
       "       'AVG_DAYS_PAST_DUE', 'DTI_RATIO', 'MOB', 'CNT_OTHER_PRODUCTS',\n",
       "       'LIMIT_TO_INCOME', 'AMT_VAR_6M', 'CBAL_SHORTTERM_LOAN',\n",
       "       'CBAL_LONGTERM_LOAN', 'HAS_LONGTERM_LOAN', 'CNT_DPD_30PLUS_6M',\n",
       "       'OCCUPATION_TYPE', 'DURATION_MAX', 'REMAINING_DURATION_MAX',\n",
       "       'TIME_TO_OP_MAX', 'RATE_AVG', 'PURCOD_MAX', 'MAX_DPD_12M',\n",
       "       'AVG_OD_DPD_12M', 'MAX_NHOMNOCIC', 'N_AVG_OVERDUE_CBAL_12M',\n",
       "       'BAD_NEXT_12M'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ac3120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1137807, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfedf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách các biến cần ép kiểu về Category (Nominal & Binary)\n",
    "categorical_cols = [\n",
    "    'OCCUPATION_TYPE', \n",
    "    'PURCOD_MAX', \n",
    "    'PURCOD_MIN',\n",
    "    'SOHUUNHA', \n",
    "    'NHANVIENBIDV',\n",
    "    'FLAG_SALARY_ACC', \n",
    "    'FLAG_DEPOSIT', \n",
    "    'FLAG_CASH_ADVANCE',\n",
    "    'HAS_SHORTTERM_LOAN', # Nếu có trong df final\n",
    "    'HAS_LONGTERM_LOAN',  # Nếu có trong df final\n",
    "    'BAD_CURRENT',        # Nếu giữ lại làm feature (thường là drop vì data leakage)\n",
    "    'XULYNO'              # Nếu giữ lại\n",
    "]\n",
    "\n",
    "# Lọc những cột thực sự tồn tại trong df (đề phòng bạn đã drop bớt)\n",
    "existing_cat_cols = [col for col in categorical_cols if col in df.columns]\n",
    "\n",
    "# Chuyển đổi\n",
    "for col in existing_cat_cols:\n",
    "    df[col] = df[col].astype('str') # Chuyển về string để EBM hiểu là category\n",
    "    oos[col] = oos[col].astype('str')\n",
    "    oot[col] = oot[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde8a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['BAD_NEXT_12M']\n",
    "y_oos = oos['BAD_NEXT_12M']\n",
    "y_oot = oot['BAD_NEXT_12M']\n",
    "X = df.drop(['BAD_NEXT_12M', 'HAS_LONGTERM_LOAN', 'AVG_OD_DPD_12M'], axis=1)\n",
    "X_oos = oos.drop(['BAD_NEXT_12M', 'HAS_LONGTERM_LOAN', 'AVG_OD_DPD_12M'], axis=1)\n",
    "X_oot = oot.drop(['BAD_NEXT_12M', 'HAS_LONGTERM_LOAN', 'AVG_OD_DPD_12M'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489ac80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 9 cặp biến tương quan cao (> 0.7):\n",
      "------------------------------------------------------------\n",
      "Biến 1 (Giữ?)                  | Biến 2 (Bỏ?)                   | Corr      \n",
      "------------------------------------------------------------\n",
      "INCOME                         | AFLIMT_AVG                     | 0.8976\n",
      "UTILIZATION_RATE               | DTI_RATIO                      | 0.8694\n",
      "BASE_AUM                       | N_AVG_DEPOSIT_12M              | 0.7862\n",
      "DURATION_MAX                   | REMAINING_DURATION_MAX         | 0.7833\n",
      "CBAL                           | AFLIMT_AVG                     | 0.7658\n",
      "DURATION_MAX                   | TIME_TO_OP_MAX                 | 0.7511\n",
      "MAX_DPD_12M                    | MAX_NHOMNOCIC                  | 0.7483\n",
      "CBAL                           | N_AVG_OVERDUE_CBAL_12M         | 0.7232\n",
      "CBAL                           | DTI_RATIO                      | 0.7229\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = X[numeric_cols].corr().abs() # Lấy trị tuyệt đối (âm hay dương đều là tương quan mạnh)\n",
    "\n",
    "# 2. Chọn ngưỡng cắt (Threshold)\n",
    "# Với EBM, ngưỡng an toàn là 0.7. Ngưỡng 0.8 là bắt buộc phải xử lý.\n",
    "threshold = 0.7\n",
    "\n",
    "# 3. Lọc ra các cặp biến vượt ngưỡng\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "# Tạo danh sách chi tiết để bạn dễ quyết định giữ ai/bỏ ai\n",
    "high_corr_pairs = []\n",
    "for col in upper.columns:\n",
    "    high_cols = upper.index[upper[col] > threshold].tolist()\n",
    "    for row in high_cols:\n",
    "        val = upper.loc[row, col]\n",
    "        high_corr_pairs.append((row, col, val))\n",
    "\n",
    "# Sắp xếp theo độ tương quan giảm dần\n",
    "high_corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 4. In kết quả\n",
    "print(f\"Tìm thấy {len(high_corr_pairs)} cặp biến tương quan cao (> {threshold}):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Biến 1 (Giữ?)':<30} | {'Biến 2 (Bỏ?)':<30} | {'Corr':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for pair in high_corr_pairs:\n",
    "    print(f\"{pair[0]:<30} | {pair[1]:<30} | {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612c396",
   "metadata": {},
   "source": [
    "Trong các mô hình dựa trên cây (Tree-based) như EBM, XGBoost, LightGBM, ngưỡng xử lý đa cộng tuyến thường lỏng hơn nhiều so với Logistic Regression. Ngưỡng vàng: Thường là 0.9 hoặc 0.95. Nếu tương quan < 0.9, mô hình vẫn đủ sức phân biệt được tín hiệu riêng biệt của từng biến."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1184669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR 1                     | IV 1   | Miss 1 || VAR 2                     | IV 2   | Miss 2 || ĐỀ XUẤT GIỮ\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">>> Đang tính toán chỉ số cho các biến...\n",
      "INCOME                    | 0.3391 | 5.0%   || AFLIMT_AVG                | 0.1496 | 0.0%   || --> INCOME (Higher IV)\n",
      "UTILIZATION_RATE          | 0.1537 | 0.0%   || DTI_RATIO                 | 0.1800 | 0.0%   || --> DTI_RATIO (Higher IV)\n",
      "BASE_AUM                  | 0.4986 | 0.0%   || N_AVG_DEPOSIT_12M         | 0.9634 | 0.0%   || --> N_AVG_DEPOSIT_12M (Higher IV)\n",
      "DURATION_MAX              | 0.0003 | 0.0%   || REMAINING_DURATION_MAX    | 0.0001 | 0.0%   || --> DURATION_MAX (Higher IV)\n",
      "CBAL                      | 0.0136 | 0.0%   || AFLIMT_AVG                | 0.1496 | 0.0%   || --> AFLIMT_AVG (Higher IV)\n",
      "DURATION_MAX              | 0.0003 | 0.0%   || TIME_TO_OP_MAX            | 0.0002 | 0.0%   || --> DURATION_MAX (Higher IV)\n",
      "MAX_DPD_12M               | 1.5983 | 0.0%   || MAX_NHOMNOCIC             | 1.4032 | 0.0%   || --> MAX_DPD_12M (Granularity)\n",
      "CBAL                      | 0.0136 | 0.0%   || N_AVG_OVERDUE_CBAL_12M    | 0.5708 | 0.0%   || --> N_AVG_OVERDUE_CBAL_12M (Higher IV)\n",
      "CBAL                      | 0.0136 | 0.0%   || DTI_RATIO                 | 0.1800 | 0.0%   || --> DTI_RATIO (Higher IV)\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      ">>> Gợi ý các biến nên LOẠI BỎ (7 biến):\n",
      "['UTILIZATION_RATE', 'MAX_NHOMNOCIC', 'REMAINING_DURATION_MAX', 'AFLIMT_AVG', 'BASE_AUM', 'CBAL', 'TIME_TO_OP_MAX']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================\n",
    "# 1. DANH SÁCH CÁC CẶP BIẾN CẦN KIỂM TRA\n",
    "# ============================================================\n",
    "high_corr_pairs = [\n",
    "    ('INCOME', 'AFLIMT_AVG'),\n",
    "    ('UTILIZATION_RATE', 'DTI_RATIO'),\n",
    "    ('BASE_AUM', 'N_AVG_DEPOSIT_12M'),\n",
    "    ('DURATION_MAX', 'REMAINING_DURATION_MAX'),\n",
    "    ('CBAL', 'AFLIMT_AVG'),\n",
    "    ('DURATION_MAX', 'TIME_TO_OP_MAX'),\n",
    "    ('MAX_DPD_12M', 'MAX_NHOMNOCIC'),\n",
    "    ('CBAL', 'N_AVG_OVERDUE_CBAL_12M'),\n",
    "    ('CBAL', 'DTI_RATIO')\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 2. HÀM TÍNH IV (INFORMATION VALUE) & MISSING RATE\n",
    "# ============================================================\n",
    "def calculate_metrics(df, target, feature):\n",
    "    # 1. Tính Missing Rate\n",
    "    missing_rate = df[feature].isna().mean()\n",
    "    \n",
    "    # 2. Tính Unique values (Độ mịn)\n",
    "    n_unique = df[feature].nunique()\n",
    "    \n",
    "    # 3. Tính IV (Phiên bản đơn giản dùng qcut)\n",
    "    try:\n",
    "        # Tạo df tạm\n",
    "        dff = pd.DataFrame({'feature': df[feature], 'target': target})\n",
    "        dff = dff.dropna()\n",
    "        \n",
    "        # Nếu là biến số -> Binning thành 10 phần\n",
    "        if pd.api.types.is_numeric_dtype(dff['feature']) and n_unique > 10:\n",
    "            dff['bin'] = pd.qcut(dff['feature'].rank(method='first'), 10, duplicates='drop')\n",
    "        else:\n",
    "            dff['bin'] = dff['feature'].astype(str)\n",
    "            \n",
    "        # Group by bin\n",
    "        grouped = dff.groupby('bin')['target'].agg(['count', 'sum'])\n",
    "        grouped['non_event'] = grouped['count'] - grouped['sum']\n",
    "        \n",
    "        # Tính %\n",
    "        grouped['pct_event'] = (grouped['sum'] + 0.5) / grouped['sum'].sum() # +0.5 để tránh log(0)\n",
    "        grouped['pct_non_event'] = (grouped['non_event'] + 0.5) / grouped['non_event'].sum()\n",
    "        \n",
    "        # WOE & IV\n",
    "        grouped['woe'] = np.log(grouped['pct_non_event'] / grouped['pct_event'])\n",
    "        grouped['iv'] = (grouped['pct_non_event'] - grouped['pct_event']) * grouped['woe']\n",
    "        \n",
    "        iv_value = grouped['iv'].sum()\n",
    "    except Exception as e:\n",
    "        iv_value = 0.0 # Lỗi thì trả về 0\n",
    "\n",
    "    return iv_value, missing_rate, n_unique\n",
    "\n",
    "# ============================================================\n",
    "# 3. CHẠY VÒNG LẶP SO SÁNH\n",
    "# ============================================================\n",
    "print(f\"{'VAR 1':<25} | {'IV 1':<6} | {'Miss 1':<6} || {'VAR 2':<25} | {'IV 2':<6} | {'Miss 2':<6} || {'ĐỀ XUẤT GIỮ'}\")\n",
    "print(\"-\" * 115)\n",
    "\n",
    "# Tập hợp tất cả các biến cần tính (để không tính lại nhiều lần)\n",
    "all_vars = set([p[0] for p in high_corr_pairs] + [p[1] for p in high_corr_pairs])\n",
    "metrics_dict = {}\n",
    "\n",
    "# Tính toán trước cho tất cả biến\n",
    "print(\">>> Đang tính toán chỉ số cho các biến...\")\n",
    "for col in all_vars:\n",
    "    if col in X.columns:\n",
    "        metrics_dict[col] = calculate_metrics(X, y_train, col)\n",
    "    else:\n",
    "        metrics_dict[col] = (0, 1.0, 0) # Không tìm thấy biến\n",
    "\n",
    "# So sánh từng cặp\n",
    "recommendations = []\n",
    "\n",
    "for v1, v2 in high_corr_pairs:\n",
    "    iv1, miss1, u1 = metrics_dict.get(v1, (0, 0, 0))\n",
    "    iv2, miss2, u2 = metrics_dict.get(v2, (0, 0, 0))\n",
    "    \n",
    "    # Logic Đề xuất:\n",
    "    # 1. Nếu Missing chênh lệch quá lớn (> 20%) -> Chọn biến ít Missing hơn\n",
    "    if abs(miss1 - miss2) > 0.2:\n",
    "        winner = v1 if miss1 < miss2 else v2\n",
    "        reason = \"Data Quality\"\n",
    "    # 2. Nếu không, chọn biến có IV cao hơn\n",
    "    elif iv1 > iv2:\n",
    "        winner = v1\n",
    "        reason = \"Higher IV\"\n",
    "    else:\n",
    "        winner = v2\n",
    "        reason = \"Higher IV\"\n",
    "        \n",
    "    # Logic đặc biệt cho trường hợp DPD vs NHOMNOCIC (Ưu tiên độ mịn)\n",
    "    if \"DPD\" in v1 and \"NHOM\" in v2: winner = v1; reason = \"Granularity\"\n",
    "    if \"DPD\" in v2 and \"NHOM\" in v1: winner = v2; reason = \"Granularity\"\n",
    "\n",
    "    print(f\"{v1:<25} | {iv1:.4f} | {miss1:.1%}   || {v2:<25} | {iv2:.4f} | {miss2:.1%}   || --> {winner} ({reason})\")\n",
    "    \n",
    "    # Lưu biến bị loại bỏ để lọc sau này\n",
    "    loser = v2 if winner == v1 else v1\n",
    "    recommendations.append(loser)\n",
    "\n",
    "print(\"-\" * 115)\n",
    "print(f\"\\n>>> Gợi ý các biến nên LOẠI BỎ ({len(set(recommendations))} biến):\")\n",
    "print(list(set(recommendations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e07d37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['UTILIZATION_RATE', 'MAX_NHOMNOCIC', 'REMAINING_DURATION_MAX', 'AFLIMT_AVG', 'BASE_AUM', 'CBAL', 'TIME_TO_OP_MAX'], axis=1, inplace=True)\n",
    "X_oos.drop(['UTILIZATION_RATE', 'MAX_NHOMNOCIC', 'REMAINING_DURATION_MAX', 'AFLIMT_AVG', 'BASE_AUM', 'CBAL', 'TIME_TO_OP_MAX'], axis=1, inplace=True)\n",
    "X_oot.drop(['UTILIZATION_RATE', 'MAX_NHOMNOCIC', 'REMAINING_DURATION_MAX', 'AFLIMT_AVG', 'BASE_AUM', 'CBAL', 'TIME_TO_OP_MAX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4188bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_parquet('X_train.parquet', index=False)\n",
    "X_oos.to_parquet('X_oos.parquet', index=False)\n",
    "X_oot.to_parquet('X_oot.parquet', index=False)\n",
    "y_train.to_frame().to_parquet('y_train.parquet', index=False)\n",
    "y_oos.to_frame().to_parquet('y_oos.parquet', index=False)\n",
    "y_oot.to_frame().to_parquet('y_oot.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
