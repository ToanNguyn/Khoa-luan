{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c6f6e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [1/6] LOADING CLEAN DATA (FROM EDA)...\n",
      "   Train: (1137807, 37) | OOS: (300317, 37) | OOT: (302113, 37)\n",
      ">>> [2/6] FEATURE ENGINEERING (ON-THE-FLY)...\n",
      "   Số lượng biến đưa vào mô hình: 45\n",
      "\n",
      ">>> [3/6] TRAINING BASELINE MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\miniconda3\\Lib\\site-packages\\interpret\\glassbox\\_ebm\\_ebm.py:871: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Kết quả Baseline:\n",
      "   [TRAIN-Base] AUC: 0.8714 | GINI: 0.7428\n",
      "   [OOS-Base] AUC: 0.8774 | GINI: 0.7547\n",
      "   [OOT-Base] AUC: 0.8755 | GINI: 0.7510\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/1529063906608/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/1529063906608/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EBM CREDIT SCORING - FULL THESIS PIPELINE\n",
    "# ============================================================\n",
    "# Tác giả: Gemini & User\n",
    "# Mục tiêu: So sánh EBM Baseline vs. EBM Optimized (Optuna)\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# Cấu hình hiển thị pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# ============================================================\n",
    "# 1. HÀM TIỆN ÍCH (UTILS)\n",
    "# ============================================================\n",
    "\n",
    "def feature_engineering_final(df_in):\n",
    "    \"\"\"\n",
    "    Tạo biến phái sinh (Feature Engineering) cho file EBM.\n",
    "    Lưu ý: KHÔNG xử lý Outlier/Missing ở đây nữa vì EDA đã làm rồi.\n",
    "    Chỉ thực hiện các phép tính toán học (Cộng trừ nhân chia, Log).\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # 1.1. Xử lý fillna tạm thời để tính toán Ratio (tránh chia cho NaN)\n",
    "    # Lưu ý: EBM tự xử lý được NaN ở biến gốc, nhưng biến Ratio cần số cụ thể\n",
    "    if 'INCOME' in df.columns:\n",
    "        income_safe = df['INCOME'].fillna(0)\n",
    "    else:\n",
    "        income_safe = 0\n",
    "        \n",
    "    if 'CBAL' in df.columns:\n",
    "        cbal_safe = df['CBAL'].fillna(0)\n",
    "    else:\n",
    "        cbal_safe = 0\n",
    "        \n",
    "    if 'AFLIMT_MAX' in df.columns:\n",
    "        limit_safe = df['AFLIMT_MAX'].replace(0, 1).fillna(1)\n",
    "    else:\n",
    "        limit_safe = 1\n",
    "\n",
    "    # 1.2. Tạo Ratios\n",
    "    # DTI: Debt to Income\n",
    "    df['RATIO_DTI'] = cbal_safe / (income_safe + 1)\n",
    "    \n",
    "    # Utilization: Dư nợ / Hạn mức\n",
    "    df['RATIO_UTILIZATION'] = cbal_safe / limit_safe\n",
    "    \n",
    "    # Payment Burden (giả định trả 3% dư nợ)\n",
    "    df['RATIO_PAYMENT_TO_INCOME'] = (cbal_safe * 0.03) / (income_safe + 1)\n",
    "    \n",
    "    # 1.3. Log Transformations (Giúp phân phối chuẩn hơn cho EBM)\n",
    "    for col in ['INCOME', 'CBAL', 'BASE_AUM']:\n",
    "        if col in df.columns:\n",
    "            # Tự động xử lý số âm bằng cách clip tại 0 trước khi log\n",
    "            df[f'{col}_LOG'] = np.log1p(df[col].clip(lower=0))\n",
    "\n",
    "    # 1.4. Interactions (Tương tác biến thủ công - Domain Knowledge)\n",
    "    # Ví dụ: DTI cao mà LTV cũng cao -> Rủi ro kép\n",
    "    if 'LTV' in df.columns:\n",
    "        df['DTI_x_LTV'] = df['RATIO_DTI'] * df['LTV']\n",
    "        \n",
    "    # Tiền gửi nhiều x Thu nhập cao -> Khách VIP (Rủi ro thấp)\n",
    "    if 'N_AVG_DEPOSIT_12M' in df.columns and 'INCOME_LOG' in df.columns:\n",
    "        df['DEPOSIT_x_INCOME'] = df['N_AVG_DEPOSIT_12M'] * df['INCOME_LOG']\n",
    "        \n",
    "    # 1.5. Clean Ratios (Cắt đuôi nhẹ cho các biến vừa tạo ra thôi)\n",
    "    # Các biến gốc đã được cap ở EDA, nhưng biến mới tạo (như DTI) có thể bị vọt\n",
    "    if 'RATIO_DTI' in df.columns:\n",
    "        df['RATIO_DTI'] = df['RATIO_DTI'].clip(0, 10)\n",
    "    if 'RATIO_UTILIZATION' in df.columns:\n",
    "        df['RATIO_UTILIZATION'] = df['RATIO_UTILIZATION'].clip(0, 5)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_gini(model, X, y, label=\"\"):\n",
    "    \"\"\"Tính Gini và in ra màn hình\"\"\"\n",
    "    # EBM predict_proba trả về xác suất [P(0), P(1)]\n",
    "    prob = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, prob)\n",
    "    gini = 2 * auc - 1\n",
    "    if label:\n",
    "        print(f\"   [{label}] AUC: {auc:.4f} | GINI: {gini:.4f}\")\n",
    "    return gini\n",
    "\n",
    "# ============================================================\n",
    "# 2. MAIN WORKFLOW\n",
    "# ============================================================\n",
    "\n",
    "print(\">>> [1/6] LOADING CLEAN DATA (FROM EDA)...\")\n",
    "\n",
    "# Đường dẫn thư mục chứa file Parquet đã xuất từ EDA\n",
    "data_path = r'C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\EBM'\n",
    "\n",
    "try:\n",
    "    # Đọc 6 file riêng biệt\n",
    "    X_train = pd.read_parquet(f'{data_path}/X_train.parquet')\n",
    "    y_train = pd.read_parquet(f'{data_path}/y_train.parquet').squeeze() # squeeze để về Series\n",
    "\n",
    "    X_val = pd.read_parquet(f'{data_path}/X_oos.parquet')\n",
    "    y_val = pd.read_parquet(f'{data_path}/y_oos.parquet').squeeze()\n",
    "\n",
    "    X_test = pd.read_parquet(f'{data_path}/X_oot.parquet')\n",
    "    y_test = pd.read_parquet(f'{data_path}/y_oot.parquet').squeeze()\n",
    "    \n",
    "    print(f\"   Train: {X_train.shape} | OOS: {X_val.shape} | OOT: {X_test.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"LỖI: Không tìm thấy file Parquet. Hãy chạy file EDA trước để xuất dữ liệu.\")\n",
    "    exit()\n",
    "\n",
    "print(\">>> [2/6] FEATURE ENGINEERING (ON-THE-FLY)...\")\n",
    "# Áp dụng hàm tạo biến phái sinh cho cả 3 tập\n",
    "X_train = feature_engineering_final(X_train)\n",
    "X_val   = feature_engineering_final(X_val)\n",
    "X_test  = feature_engineering_final(X_test)\n",
    "\n",
    "# Cập nhật danh sách feature sau khi tạo thêm biến mới\n",
    "feature_cols = X_train.columns.tolist()\n",
    "print(f\"   Số lượng biến đưa vào mô hình: {len(feature_cols)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CẤU HÌNH MONOTONICITY (Cập nhật theo biến thực tế có trong X)\n",
    "# ------------------------------------------------------------\n",
    "# Dictionary định nghĩa hướng rủi ro (Logic nghiệp vụ)\n",
    "mono_constraints_dict = {\n",
    "    # Tăng -> Risk Tăng (1)\n",
    "    'MAX_DPD_12M_OBS': 1, 'AVG_OD_DPD_12M': 1, 'SUM_ALL_OD_12M': 1, \n",
    "    'CBAL_AVG': 1, 'LTV': 1, 'RATE_AVG': 1,\n",
    "    'RATIO_DTI': 1, 'RATIO_UTILIZATION': 1, 'RATIO_PAYMENT_TO_INCOME': 1,\n",
    "    'DTI_x_LTV': 1,\n",
    "\n",
    "    # Tăng -> Risk Giảm (-1)\n",
    "    'INCOME': -1, 'INCOME_LOG': -1,\n",
    "    'BASE_AUM': -1, 'AUM_LOG': -1,\n",
    "    'N_AVG_DEPOSIT_12M': -1, 'DEPOSIT_x_INCOME': -1,\n",
    "    'SOHUUNHA': -1,\n",
    "    \n",
    "    # Không ràng buộc (0)\n",
    "    'TUOI': 0, 'DURATION_MAX': 0\n",
    "}\n",
    "\n",
    "# Tạo list constraints khớp với thứ tự cột trong X_train\n",
    "# Nếu biến không có trong dict, mặc định là 0\n",
    "mono_constraints_list = [mono_constraints_dict.get(col, 0) for col in feature_cols]\n",
    "\n",
    "# ============================================================\n",
    "# 3. BASELINE MODEL\n",
    "# ============================================================\n",
    "print(\"\\n>>> [3/6] TRAINING BASELINE MODEL...\")\n",
    "\n",
    "ebm_base = ExplainableBoostingClassifier(\n",
    "    monotone_constraints=mono_constraints_list, \n",
    "    interactions=0,               \n",
    "    learning_rate=1,    \n",
    "    random_state=42,    \n",
    "    n_jobs=-1,  \n",
    "    early_stopping_rounds=10    # Dừng sớm nếu không cải thiện trên tập Validation (cần truyền eval_set)\n",
    ")\n",
    "\n",
    "# Fit mô hình (Có sử dụng tập Validation để Early Stopping)\n",
    "ebm_base.fit(X_train, y_train) \n",
    "# Lưu ý: EBM mặc định sẽ tự tách một phần train ra làm val nội bộ nếu không đưa eval_set.\n",
    "# Nếu muốn chuẩn chỉ dùng OOS làm val:\n",
    "# ebm_base.fit(X_train, y_train, eval_set=[(X_val, y_val)]) \n",
    "\n",
    "# Đánh giá Baseline\n",
    "print(\"   Kết quả Baseline:\")\n",
    "gini_train = calculate_gini(ebm_base, X_train, y_train, \"TRAIN-Base\")\n",
    "gini_base_oos = calculate_gini(ebm_base, X_val, y_val, \"OOS-Base\")\n",
    "gini_base_oot = calculate_gini(ebm_base, X_test, y_test, \"OOT-Base\")\n",
    "\n",
    "# Hiển thị Global Explanation (Feature Importance)\n",
    "show(ebm_base.explain_global()) # Uncomment nếu chạy trên Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce3c9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C_GIOITINH',\n",
       " 'TTHONNHAN',\n",
       " 'NHANVIENBIDV',\n",
       " 'BASE_AUM',\n",
       " 'TUOI',\n",
       " 'INCOME',\n",
       " 'CBAL',\n",
       " 'AFLIMT_AVG',\n",
       " 'LTV',\n",
       " 'N_AVG_DEPOSIT_12M',\n",
       " 'FLAG_SALARY_ACC',\n",
       " 'FLAG_DEPOSIT',\n",
       " 'UTILIZATION_RATE',\n",
       " 'CNT_CREDIT_CARDS',\n",
       " 'AMT_CASH_ADVANCE_12M',\n",
       " 'PCT_PAYMENT_TO_BALANCE',\n",
       " 'CNT_MIN_PAY_6M',\n",
       " 'AVG_DAYS_PAST_DUE',\n",
       " 'DTI_RATIO',\n",
       " 'MOB',\n",
       " 'CNT_OTHER_PRODUCTS',\n",
       " 'LIMIT_TO_INCOME',\n",
       " 'AMT_VAR_6M',\n",
       " 'CBAL_SHORTTERM_LOAN',\n",
       " 'CBAL_LONGTERM_LOAN',\n",
       " 'HAS_LONGTERM_LOAN',\n",
       " 'CNT_DPD_30PLUS_6M',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'DURATION_MAX',\n",
       " 'REMAINING_DURATION_MAX',\n",
       " 'TIME_TO_OP_MAX',\n",
       " 'RATE_AVG',\n",
       " 'PURCOD_MAX',\n",
       " 'MAX_DPD_12M',\n",
       " 'AVG_OD_DPD_12M',\n",
       " 'MAX_NHOMNOCIC',\n",
       " 'N_AVG_OVERDUE_CBAL_12M',\n",
       " 'RATIO_DTI',\n",
       " 'RATIO_UTILIZATION',\n",
       " 'RATIO_PAYMENT_TO_INCOME',\n",
       " 'INCOME_LOG',\n",
       " 'CBAL_LOG',\n",
       " 'BASE_AUM_LOG',\n",
       " 'DTI_x_LTV',\n",
       " 'DEPOSIT_x_INCOME']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebcb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # 4. OPTUNA TUNING – EBM OPTIMIZED\n",
    "# # ============================================================\n",
    "# from optuna.pruners import HyperbandPruner\n",
    "# print(\"\\n>>> [3/6] OPTIMIZING MODEL WITH OPTUNA...\")\n",
    "\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.05),\n",
    "#         \"interactions\": trial.suggest_int(\"interactions\", 0, 20),\n",
    "#         \"max_bins\": trial.suggest_int(\"max_bins\", 128, 512),\n",
    "#         \"outer_bags\": trial.suggest_int(\"outer_bags\", 4, 20),\n",
    "#         \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 100),\n",
    "#     }\n",
    "\n",
    "#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     gini_scores = []\n",
    "\n",
    "#     for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "#         X_tr, X_va = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "#         y_tr, y_va = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "#         model = ExplainableBoostingClassifier(\n",
    "#             monotone_constraints=mono_constraints_list,\n",
    "#             random_state=42,\n",
    "#             n_jobs=-1,\n",
    "#             **params\n",
    "#         )\n",
    "\n",
    "#         model.fit(X_tr, y_tr)\n",
    "\n",
    "#         prob = model.predict_proba(X_va)[:, 1]\n",
    "#         auc = roc_auc_score(y_va, prob)\n",
    "#         gini_scores.append(2*auc - 1)\n",
    "\n",
    "#     return np.mean(gini_scores)\n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\",\n",
    "#     pruner=optuna.pruners.MedianPruner(\n",
    "#         n_startup_trials=5,\n",
    "#         n_warmup_steps=1,\n",
    "#         interval_steps=1\n",
    "\n",
    "#     ))\n",
    "# study.optimize(objective, n_trials=50)\n",
    "\n",
    "# print(\"\\n>>> BEST PARAMETERS FOUND:\")\n",
    "# print(study.best_params)\n",
    "# print(f\"Best Gini (OOS): {study.best_value:.4f}\")\n",
    "\n",
    "# # Train lại model optimized\n",
    "# ebm_opt = ExplainableBoostingClassifier(\n",
    "#     monotone_constraints=mono_constraints_list,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     **study.best_params\n",
    "# )\n",
    "# ebm_opt.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\n>>> [4/6] GINI – EBM OPTIMIZED\")\n",
    "# gini_opt_oos = calculate_gini(ebm_opt, X_val, y_val, \"OOS-Optimized\")\n",
    "# gini_opt_oot = calculate_gini(ebm_opt, X_test, y_test, \"OOT-Optimized\")\n",
    "\n",
    "# # Visualization\n",
    "# fig1 = plot_optimization_history(study)\n",
    "# fig2 = plot_param_importances(study)\n",
    "# fig1.show()\n",
    "# fig2.show()\n",
    "\n",
    "# # Save model\n",
    "# pickle.dump(ebm_opt, open(\"ebm_optimized.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df8d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna.visualization as vis\n",
    "\n",
    "# # 1. Vẽ Slice Plot cho tất cả các tham số\n",
    "# fig_slice = vis.plot_slice(study)\n",
    "# fig_slice.show()\n",
    "\n",
    "# # 2. Hoặc vẽ Slice Plot cho một vài tham số quan trọng bạn muốn đưa vào bài viết\n",
    "# fig_specific = vis.plot_slice(study, params=[\"learning_rate\", \"min_samples_leaf\", \"interactions\"])\n",
    "# fig_specific.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fd7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train lại model optimized\n",
    "# ebm_opt = ExplainableBoostingClassifier(\n",
    "#     monotone_constraints=mono_constraints_list,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     learning_rate=0.041459457759190334, \n",
    "#     interactions=8, \n",
    "#     max_bins=325, \n",
    "#     outer_bags=11, \n",
    "#     min_samples_leaf=27\n",
    "# )\n",
    "# ebm_opt.fit(X_train, y_train)\n",
    "\n",
    "# print(\"\\n>>> [4/6] GINI – EBM OPTIMIZED\")\n",
    "# gini_opt_oos = calculate_gini(ebm_opt, X_val, y_val, \"OOS-Optimized\")\n",
    "# gini_opt_oot = calculate_gini(ebm_opt, X_test, y_test, \"OOT-Optimized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c4e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(ebm_opt, open(\"ebm_optimized.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdeb548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # 5. MODEL EXPLAINABILITY\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n>>> [5/6] EXPLAINABILITY REPORT...\")\n",
    "\n",
    "# # 5.1. GLOBAL FEATURE IMPORTANCE\n",
    "# global_importance = ebm_opt.explain_global()\n",
    "\n",
    "# print(\"\\n>>> TOP FEATURES (Global Importance):\")\n",
    "# for i, (name, score) in enumerate(zip(\n",
    "#         global_importance.data()['names'],\n",
    "#         global_importance.data()['scores'])):\n",
    "#     print(f\"{i+1:2d}. {name}: {score:.4f}\")\n",
    "\n",
    "# # 5.2. HIỂN THỊ BẰNG TRÌNH DUYỆT (nếu chạy trong notebook thì hiện ngay)\n",
    "# try:\n",
    "#     show(global_importance)\n",
    "# except:\n",
    "#     print(\"   (Không thể render giao diện trực tiếp — vẫn tiếp tục.)\")\n",
    "\n",
    "# # 5.3. LOCAL EXPLANATION (giải thích 1 khách hàng bất kỳ)\n",
    "# sample_index = 0 \n",
    "# sample_X = X_test.iloc[[0]]  # vẫn là DataFrame 1 hàng\n",
    "# sample_y = y_test.iloc[0]    # Series scalar, 1D\n",
    "\n",
    "# local_exp = ebm_opt.explain_local(X_test, y_test)\n",
    "#   # Series\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n>>> LOCAL EXPLANATION SAMPLE:\")\n",
    "# show(local_exp)\n",
    "# print(local_exp.data(0))\n",
    "\n",
    "\n",
    "# try:\n",
    "#     importances = ebm_opt.term_importances()\n",
    "# except:\n",
    "#     try:\n",
    "#         importances = ebm_opt.feature_importances_\n",
    "#     except:\n",
    "#         raise ValueError(\"Không tìm thấy thuộc tính term_importances hoặc feature_importances.\")\n",
    "\n",
    "# terms = ebm_opt.term_names_\n",
    "\n",
    "# print(\"\\n>>> TOP INTERACTIONS:\")\n",
    "# for name, imp in sorted(zip(terms, importances), key=lambda x: x[1], reverse=True):\n",
    "#     if \"&\" in name:  # interaction luôn có ký tự &\n",
    "#         print(f\"{name}: {imp:.4f}\")\n",
    "\n",
    "\n",
    "# # Lưu phần explain vào file\n",
    "# pickle.dump(global_importance, open(\"ebm_global_exp.pkl\", \"wb\"))\n",
    "# pickle.dump(local_exp, open(\"ebm_local_exp.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026eeb2b",
   "metadata": {},
   "source": [
    "Global importance: \n",
    "- Giá trị tuyệt đối trung bình của điểm số (Average Absolute Score) mà biến đó đóng góp vào dự báo trên toàn bộ tập dữ liệu: Trung bình, biến này làm thay đổi dự đoán (log-odds) bao nhiêu đơn vị? Số càng lớn = Biến càng quan trọng.\n",
    "\n",
    "Cách tính, ví dụ với biến SOHUUNHA:\n",
    "- Bước 1: Tính Score cho từng người: Với mỗi khách hàng trong tập dữ liệu, mô hình xem khách hàng đó có nhà hay không (SOHUUNHA = 1 hoặc 0). Sau đó, nó tra cứu trong bảng hàm hình dạng xem giá trị đó tương ứng với bao nhiêu điểm (ví dụ: Có nhà thì $-0.8$ điểm, không nhà thì $+1.3$ điểm rủi ro).\n",
    "\n",
    "- Bước 2: Lấy trị tuyệt đối: Vì mô hình muốn đo lường mức độ tác động (dù là làm tăng hay giảm rủi ro đều được coi là quan trọng), nên nó lấy trị tuyệt đối của tất cả các điểm số đó: $|-0.8| = 0.8$ và $|1.3| = 1.3$.\n",
    "\n",
    "- Bước 3: Tính trung bình: Cộng tất cả các trị tuyệt đối này lại và chia cho tổng số khách hàng. Kết quả cuối cùng chính là con số bạn thấy.\n",
    "\n",
    "Tác động của biến SOHUUNHA: \n",
    "- SOHUUNHA ≈ 0 (Không sở hữu nhà): * Giá trị Score nằm ở mức khoảng +0.8. Những khách hàng không có nhà riêng có xu hướng làm tăng xác suất của biến mục tiêu\n",
    "- SOHUUNHA ≈ 1 (Có sở hữu nhà): * Giá trị Score giảm mạnh xuống mức khoảng -1.5. Việc sở hữu nhà đóng góp một giá trị âm rất lớn vào tổng điểm. Điều này làm giảm mạnh xác suất xảy ra biến mục tiêu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9be502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # 6. FINAL REPORT – PSI, COMPARISON, SUMMARY\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n>>> [6/6] FINAL MODEL REPORT...\")\n",
    "\n",
    "# # 6.1. Tính PSI của 2 biến chính giữa Train – OOT\n",
    "# psi_report = {}\n",
    "# for col in [\"INCOME\", \"CBAL\", \"RATIO_DTI\", \"RATIO_UTILIZATION\"]:\n",
    "#     try:\n",
    "#         psi_report[col] = calculate_psi(\n",
    "#             X_train[col].values,\n",
    "#             X_test[col].values\n",
    "#         )\n",
    "#     except:\n",
    "#         psi_report[col] = None\n",
    "\n",
    "# print(\"\\n>>> PSI REPORT (Train → OOT):\")\n",
    "# for k,v in psi_report.items():\n",
    "#     print(f\"   {k}: {v:.4f}\")\n",
    "\n",
    "# # 6.2. So sánh Gini Baseline vs Optimized\n",
    "# print(\"\\n>>> GINI COMPARISON\")\n",
    "# print(f\"Baseline – OOS: {gini_base_oos:.4f}\")\n",
    "# print(f\"Optimized – OOS: {gini_opt_oos:.4f}\")\n",
    "# print(f\"Baseline – OOT: {gini_base_oot:.4f}\")\n",
    "# print(f\"Optimized – OOT: {gini_opt_oot:.4f}\")\n",
    "\n",
    "# # 6.3. Lưu bản summary ra file TXT\n",
    "# # Best Hyperparameters:\n",
    "# # {study.best_params}\n",
    "# # \"\"\"\n",
    "# summary_text = f\"\"\"\n",
    "# =============================\n",
    "# EBM CREDIT SCORING SUMMARY\n",
    "# =============================\n",
    "\n",
    "# GINI – OOS:\n",
    "#  - Baseline:  {gini_base_oos:.4f}\n",
    "#  - Optimized: {gini_opt_oos:.4f}\n",
    "\n",
    "# GINI – OOT:\n",
    "#  - Baseline:  {gini_base_oot:.4f}\n",
    "#  - Optimized: {gini_opt_oot:.4f}\n",
    "\n",
    "# PSI (Train → OOT):\n",
    "# {psi_report}\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# with open(\"model_summary.txt\", \"w\") as f:\n",
    "#     f.write(summary_text)\n",
    "\n",
    "# print(\"\\n>>> SUMMARY EXPORTED → model_summary.txt\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac64cb7",
   "metadata": {},
   "source": [
    "Mô hình rất ổn định khi chuyển từ TRAIN → OOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99c63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6.4. Tính PSI cho Score (Xác suất dự báo) - QUAN TRỌNG NHẤT\n",
    "# prob_train = ebm_opt.predict_proba(X_train)[:, 1]\n",
    "# prob_oot = ebm_opt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# psi_score = calculate_psi(prob_train, prob_oot)\n",
    "# print(f\"\\n>>> FINAL MODEL STABILITY (PSI Score): {psi_score:.4f}\")\n",
    "# if psi_score < 0.1:\n",
    "#     print(\"    => Kết luận: Mô hình cực kỳ ổn định qua thời gian.\")\n",
    "# elif psi_score < 0.25:\n",
    "#     print(\"    => Kết luận: Mô hình có sự biến động nhẹ, cần giám sát.\")\n",
    "# else:\n",
    "#     print(\"    => Kết luận: CẢNH BÁO! Mô hình không ổn định, cần kiểm tra lại dữ liệu OOT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7176f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "# # ============================================================\n",
    "# # 7. NÂNG CAO: MONOTONICITY, CONFUSION MATRIX & RATING\n",
    "# # ============================================================\n",
    "# print(\"\\n>>> [7/7] ADVANCED ANALYTICS & RATING...\")\n",
    "\n",
    "# # 7.1. Kiểm tra tính đơn điệu (Monotonicity Check)\n",
    "# # EBM lưu các hàm đóng góp trong explain_global. \n",
    "# # Bạn có thể vẽ lại để kiểm tra xem các biến ép đơn điệu có đúng đường thẳng/bậc thang không.\n",
    "# def check_monotonicity(ebm_model, feature_name):\n",
    "#     exp = ebm_model.explain_global(name=feature_name)\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.step(exp.data(0)['names'], exp.data(0)['scores'], where='post')\n",
    "#     plt.title(f\"Monotonicity Check: {feature_name}\")\n",
    "#     plt.xlabel(feature_name)\n",
    "#     plt.ylabel(\"Logit Contribution\")\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# # Chạy thử cho 2 biến tiêu biểu\n",
    "# # check_monotonicity(ebm_opt, 'MAX_DPD_12M_OBS') \n",
    "# # check_monotonicity(ebm_opt, 'LTV')\n",
    "\n",
    "# # 7.2. Ma trận nhầm lẫn tại điểm cắt (Cut-off)\n",
    "# # Giả sử ngân hàng chọn Cut-off là 10% (PD > 0.1 là từ chối)\n",
    "# threshold = 0.1\n",
    "# y_prob_oot = ebm_opt.predict_proba(X_test)[:, 1]\n",
    "# y_pred_oot = (y_prob_oot >= threshold).astype(int)\n",
    "\n",
    "# print(f\"\\n>>> CONFUSION MATRIX (At Threshold {threshold}):\")\n",
    "# cm = confusion_matrix(y_test, y_pred_oot)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Good (0)', 'Bad (1)'])\n",
    "# disp.plot(cmap='Blues')\n",
    "# plt.title(f\"Confusion Matrix at Cut-off {threshold}\")\n",
    "# plt.show()\n",
    "\n",
    "# print(classification_report(y_test, y_pred_oot))\n",
    "\n",
    "# # 7.3. Phân hạng khách hàng (Credit Rating)\n",
    "# def assign_rating(pd):\n",
    "#     if pd <= 0.01: return 'AAA (Rất an toàn)'\n",
    "#     if pd <= 0.03: return 'AA'\n",
    "#     if pd <= 0.05: return 'A'\n",
    "#     if pd <= 0.10: return 'BBB'\n",
    "#     if pd <= 0.20: return 'BB'\n",
    "#     if pd <= 0.50: return 'B'\n",
    "#     return 'C (Rủi ro cao - Từ chối)'\n",
    "\n",
    "# # Tạo bảng kết quả cuối cùng cho tập Test\n",
    "# df_result = pd.DataFrame({\n",
    "#     'Actual': y_test.values,\n",
    "#     'PD': y_prob_oot\n",
    "# })\n",
    "\n",
    "# df_result['Rating'] = df_result['PD'].apply(assign_rating)\n",
    "\n",
    "# print(\"\\n>>> THỐNG KÊ HẠNG KHÁCH HÀNG TRÊN TẬP OOT:\")\n",
    "# rating_dist = df_result['Rating'].value_counts().sort_index()\n",
    "# print(rating_dist)\n",
    "\n",
    "# # Tính tỷ lệ nợ xấu thực tế trên mỗi hạng (Để kiểm tra tính phân tách)\n",
    "# bad_rate_by_rating = df_result.groupby('Rating')['Actual'].mean()\n",
    "# print(\"\\n>>> TỶ LỆ NỢ XẤU THỰC TẾ THEO HẠNG (Bad Rate by Grade):\")\n",
    "# print(bad_rate_by_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf28fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # 8. CREDIT SCORECARD CALCULATION (300 - 850)\n",
    "# # ============================================================\n",
    "# print(\"\\n>>> [8/7] CONVERTING PD TO CREDIT SCORE (300-850)...\")\n",
    "\n",
    "# def calculate_credit_score(pd, pdo=20, base_score=600, base_odds=50):\n",
    "#     \"\"\"\n",
    "#     Chuyển đổi PD sang Credit Score dựa trên công thức chuẩn:\n",
    "#     Score = Offset + Factor * ln(odds)\n",
    "#     - pdo: Points to Double the Odds (thường là 20 hoặc 50)\n",
    "#     - base_score: Điểm cơ sở (ví dụ 600 điểm)\n",
    "#     - base_odds: Tỷ lệ odds tương ứng với điểm cơ sở (ví dụ 50:1)\n",
    "#     \"\"\"\n",
    "#     # Tránh chia cho 0 hoặc log(0)\n",
    "#     pd = np.clip(pd, 0.0001, 0.9999)\n",
    "    \n",
    "#     factor = pdo / np.log(2)\n",
    "#     offset = base_score - factor * np.log(base_odds)\n",
    "    \n",
    "#     odds = (1 - pd) / pd\n",
    "#     score = offset + factor * np.log(odds)\n",
    "    \n",
    "#     return np.round(score).astype(int)\n",
    "\n",
    "# # Áp dụng cho tập Test (OOT)\n",
    "# df_result['Credit_Score'] = calculate_credit_score(df_result['PD'])\n",
    "\n",
    "# # Giới hạn điểm trong khoảng 300 - 850 (như chuẩn FICO)\n",
    "# df_result['Credit_Score'] = df_result['Credit_Score'].clip(300, 850)\n",
    "\n",
    "# print(\"\\n>>> THỐNG KÊ ĐIỂM TÍN DỤNG TRÊN TẬP OOT:\")\n",
    "# print(df_result['Credit_Score'].describe())\n",
    "\n",
    "# # Vẽ biểu đồ phân phối điểm số\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df_result['Credit_Score'], bins=50, color='skyblue', edgecolor='black')\n",
    "# plt.axvline(df_result['Credit_Score'].mean(), color='red', linestyle='dashed', linewidth=2, label='Average Score')\n",
    "# plt.title('Distribution of Credit Scores (OOT Set)')\n",
    "# plt.xlabel('Credit Score')\n",
    "# plt.ylabel('Number of Customers')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Kiểm tra sự tương quan giữa Hạng và Điểm trung bình\n",
    "# print(\"\\n>>> ĐIỂM TRUNG BÌNH THEO HẠNG:\")\n",
    "# print(df_result.groupby('Rating')['Credit_Score'].mean().sort_values(ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
