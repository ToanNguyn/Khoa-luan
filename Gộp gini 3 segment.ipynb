{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec100a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (1740237, 5)\n",
      "TRAIN: GINI = 0.6676\n",
      "OOS: GINI = 0.6858\n",
      "OOT: GINI = 0.6850\n",
      "\n",
      "KS = 0.516161998500056 | Cut-off = 0.07725416741398945\n",
      "Cutpoints: [0.00195221 0.00361638 0.00902699 0.02013405 0.03356657 0.06590865\n",
      " 0.12449665 0.18416011 0.27048425]\n",
      "  RATING      SCORE_RANGE   COUNT       PCT   MEAN_PD  DEFAULT_RATE\n",
      "0    AAA  892.84 ‚Üí 938.79  146583  0.084232  0.001123      0.001044\n",
      "1    AA+  875.00 ‚Üí 892.83  108375  0.062276  0.002837      0.003091\n",
      "2     AA  848.45 ‚Üí 875.00  242294  0.139230  0.005905      0.006199\n",
      "3    AA-  824.97 ‚Üí 848.44  246007  0.141364  0.014125      0.013975\n",
      "4     A+  809.83 ‚Üí 824.97  178195  0.102397  0.026183      0.025741\n",
      "5      A  789.38 ‚Üí 809.83  211833  0.121727  0.048107      0.047434\n",
      "6     A-  769.16 ‚Üí 789.38  256994  0.147678  0.093657      0.092940\n",
      "7    BBB  755.82 ‚Üí 769.16  162797  0.093549  0.151477      0.152914\n",
      "8     BB  741.51 ‚Üí 755.82  107816  0.061955  0.220227      0.214950\n",
      "9      B  677.17 ‚Üí 741.50   79343  0.045593  0.375097      0.375723\n",
      "\n",
      "‚úî Xu·∫•t file FINAL_MODEL_SCORED_ALL.parquet th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from optbinning import OptimalBinning\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD 3 FILE PD_CALIBRATED\n",
    "# ============================================================\n",
    "\n",
    "segment_files = [\n",
    "    r'C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\Log reg\\seg1_pd_calibrated.parquet',\n",
    "    r\"C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\Log reg\\seg2_pd_calibrated.parquet\",\n",
    "    r\"C:\\Users\\PC\\Documents\\GitHub\\Khoa-luan\\Log reg\\seg3_pd_calibrated.parquet\"\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for f in segment_files:\n",
    "    temp_df = pd.read_parquet(f)\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "df_total = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Loaded:\", df_total.shape)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. T√çNH SCORE T·ª™ PD\n",
    "# ============================================================\n",
    "\n",
    "PDO = 20\n",
    "ODDS0 = 50\n",
    "SCORE0 = 600\n",
    "\n",
    "Factor = PDO / np.log(2)\n",
    "Offset = SCORE0 + Factor * np.log(ODDS0)\n",
    "\n",
    "def pd_to_score(pd):\n",
    "    pd = np.clip(pd, 1e-6, 1-1e-6)\n",
    "    log_odds = np.log(pd / (1-pd))\n",
    "    return Offset - Factor * log_odds\n",
    "\n",
    "df_total[\"SCORE\"] = pd_to_score(df_total[\"PD\"])\n",
    "\n",
    "df_score_output = df_total.copy()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. GINI CHUNG (TRAIN / OOS / OOT)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_gini(y, p):\n",
    "    auc = roc_auc_score(y, p)\n",
    "    return 2 * auc - 1\n",
    "\n",
    "for dtype in [\"TRAIN\", \"OOS\", \"OOT\"]:\n",
    "    subset = df_total[df_total[\"DATA_TYPE\"] == dtype]\n",
    "    gini = calculate_gini(subset[\"y\"], subset[\"PD\"])\n",
    "    print(f\"{dtype}: GINI = {gini:.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. KS ‚Äì CUT-OFF TR√äN TRAIN\n",
    "# ============================================================\n",
    "\n",
    "train_df = df_total[df_total[\"DATA_TYPE\"]==\"TRAIN\"]\n",
    "\n",
    "fpr, tpr, thr = roc_curve(train_df[\"y\"], train_df[\"PD\"])\n",
    "ks = (tpr - fpr).max()\n",
    "ks_cut = thr[np.argmax(tpr - fpr)]\n",
    "\n",
    "print(\"\\nKS =\", ks, \"| Cut-off =\", ks_cut)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. OPTBINNING ‚Äì FIT TR√äN TRAIN PD\n",
    "# ============================================================\n",
    "\n",
    "optb = OptimalBinning(dtype=\"numerical\", monotonic_trend=\"ascending\", max_n_bins=10)\n",
    "optb.fit(train_df[\"PD\"], train_df[\"y\"])\n",
    "\n",
    "cuts = optb.splits\n",
    "print(\"Cutpoints:\", cuts)\n",
    "\n",
    "df_score_output[\"BIN\"] = np.digitize(df_score_output[\"PD\"], cuts, right=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. MAP BIN ‚Üí RATING\n",
    "# ============================================================\n",
    "\n",
    "rating_labels = [\"AAA\",\"AA+\",\"AA\",\"AA-\",\"A+\",\"A\",\"A-\",\"BBB\",\"BB\",\"B\"]\n",
    "\n",
    "bin_mean_pd = df_score_output.groupby(\"BIN\")[\"PD\"].mean().sort_values()\n",
    "bin_to_rating = {b: rating_labels[i] for i, b in enumerate(bin_mean_pd.index)}\n",
    "\n",
    "df_score_output[\"RATING\"] = df_score_output[\"BIN\"].map(bin_to_rating)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. SUMMARY ‚Äì THEO KHO·∫¢NG ƒêI·ªÇM\n",
    "# ============================================================\n",
    "\n",
    "summary_rows = []\n",
    "for rating in rating_labels:\n",
    "    df_r = df_score_output[df_score_output[\"RATING\"] == rating]\n",
    "    if df_r.empty:\n",
    "        summary_rows.append([rating, None, None, 0, 0, None, None])\n",
    "        continue\n",
    "\n",
    "    score_min = df_r[\"SCORE\"].min()\n",
    "    score_max = df_r[\"SCORE\"].max()\n",
    "    pd_mean = df_r[\"PD\"].mean()\n",
    "    def_rate = df_r[\"y\"].mean()\n",
    "\n",
    "    summary_rows.append([\n",
    "        rating,\n",
    "        f\"{score_min:.2f} ‚Üí {score_max:.2f}\",\n",
    "        len(df_r),\n",
    "        len(df_r) / len(df_score_output),\n",
    "        pd_mean,\n",
    "        def_rate\n",
    "    ])\n",
    "\n",
    "df_rating_summary = pd.DataFrame(summary_rows, columns=[\n",
    "    \"RATING\", \"SCORE_RANGE\", \"COUNT\", \"PCT\", \"MEAN_PD\", \"DEFAULT_RATE\"\n",
    "])\n",
    "\n",
    "print(df_rating_summary)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. EXPORT MASTER FILE\n",
    "# ============================================================\n",
    "\n",
    "df_score_output.to_parquet(\"FINAL_MODEL_SCORED_ALL.parquet\", index=False)\n",
    "print(\"\\n‚úî Xu·∫•t file FINAL_MODEL_SCORED_ALL.parquet th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1070a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìä B√ÅO C√ÅO CH·ªà S·ªê N√ÇNG CAO - LOGISTIC REGRESSION\n",
      "========================================\n",
      ">>> REPORT FOR: OOT DATASET\n",
      "   ‚Ä¢ KS Statistic:       0.5379 (53.79%)\n",
      "   ‚Ä¢ Brier Score:        0.049326\n",
      "   ‚Ä¢ Capture Rate @ 10%: 43.27%\n",
      "   ‚Ä¢ Capture Rate @ 20%: 66.08%\n",
      "------------------------------------------------------------\n",
      ">>> STABILITY (PSI - Train vs OOT): 0.0308\n",
      "   ‚úÖ PSI < 0.1: M√¥ h√¨nh r·∫•t ·ªïn ƒë·ªãnh.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# ============================================================\n",
    "# 1. H√ÄM T√çNH TO√ÅN C√ÅC CH·ªà S·ªê N√ÇNG CAO (KS, BRIER, CAPTURE RATE)\n",
    "# ============================================================\n",
    "def calculate_advanced_metrics_from_df(df, target_col='y', prob_col='PD', label=\"\"):\n",
    "    # L·∫•y d·ªØ li·ªáu\n",
    "    y_true = df[target_col].values\n",
    "    y_prob = df[prob_col].values\n",
    "    \n",
    "    # --- A. T√≠nh KS Statistic (Tr√™n t·∫≠p OOT) ---\n",
    "    # KS ƒëo ƒë·ªô t√°ch bi·ªát gi·ªØa Good v√† Bad\n",
    "    prob_good = y_prob[y_true == 0]\n",
    "    prob_bad  = y_prob[y_true == 1]\n",
    "    ks_stat, p_value = ks_2samp(prob_good, prob_bad)\n",
    "    \n",
    "    # --- B. T√≠nh Brier Score ---\n",
    "    # ƒêo ƒë·ªô ch√≠nh x√°c c·ªßa x√°c su·∫•t (c√†ng th·∫•p c√†ng t·ªët)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    \n",
    "    # --- C. T√≠nh Bad Capture Rate (Lift) ---\n",
    "    # T·ª∑ l·ªá n·ª£ x·∫•u b·∫Øt ƒë∆∞·ª£c trong nh√≥m r·ªßi ro nh·∫•t (Top 10%, 20%)\n",
    "    df_temp = df.copy()\n",
    "    df_temp = df_temp.sort_values(by=prob_col, ascending=False) # Sort PD gi·∫£m d·∫ßn (R·ªßi ro cao l√™n ƒë·∫ßu)\n",
    "    \n",
    "    total_bads = df_temp[target_col].sum()\n",
    "    n_rows = len(df_temp)\n",
    "    \n",
    "    # Top 10%\n",
    "    top_10_idx = int(n_rows * 0.1)\n",
    "    bads_in_top_10 = df_temp.iloc[:top_10_idx][target_col].sum()\n",
    "    capture_rate_10 = bads_in_top_10 / total_bads if total_bads > 0 else 0\n",
    "    \n",
    "    # Top 20%\n",
    "    top_20_idx = int(n_rows * 0.2)\n",
    "    bads_in_top_20 = df_temp.iloc[:top_20_idx][target_col].sum()\n",
    "    capture_rate_20 = bads_in_top_20 / total_bads if total_bads > 0 else 0\n",
    "    \n",
    "    print(f\">>> REPORT FOR: {label}\")\n",
    "    print(f\"   ‚Ä¢ KS Statistic:       {ks_stat:.4f} ({(ks_stat*100):.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Brier Score:        {brier:.6f}\")\n",
    "    print(f\"   ‚Ä¢ Capture Rate @ 10%: {capture_rate_10:.2%}\")\n",
    "    print(f\"   ‚Ä¢ Capture Rate @ 20%: {capture_rate_20:.2%}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# 2. H√ÄM T√çNH PSI (ƒê·ªò ·ªîN ƒê·ªäNH - TRAIN vs OOT)\n",
    "# ============================================================\n",
    "def calculate_psi_score(expected, actual, buckets=10):\n",
    "    # expected: Score/PD t·∫≠p Train\n",
    "    # actual: Score/PD t·∫≠p OOT\n",
    "    \n",
    "    # Chia bin d·ª±a tr√™n ph√¢n ph·ªëi c·ªßa t·∫≠p Train (Expected)\n",
    "    breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "    breakpoints = np.percentile(expected, breakpoints)\n",
    "    \n",
    "    # Tr√°nh l·ªói tr√πng bin\n",
    "    breakpoints = np.unique(breakpoints)\n",
    "    \n",
    "    # T√≠nh % t·ª∑ tr·ªçng\n",
    "    expected_percents = np.histogram(expected, bins=breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(actual, bins=breakpoints)[0] / len(actual)\n",
    "    \n",
    "    # X·ª≠ l√Ω division by zero (th√™m m·ªôt l∆∞·ª£ng c·ª±c nh·ªè)\n",
    "    expected_percents = np.where(expected_percents == 0, 0.0001, expected_percents)\n",
    "    actual_percents = np.where(actual_percents == 0, 0.0001, actual_percents)\n",
    "    \n",
    "    # C√¥ng th·ª©c PSI\n",
    "    psi_value = np.sum((expected_percents - actual_percents) * np.log(expected_percents / actual_percents))\n",
    "    \n",
    "    return psi_value\n",
    "\n",
    "# ============================================================\n",
    "# 3. TH·ª∞C HI·ªÜN T√çNH TO√ÅN\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"üìä B√ÅO C√ÅO CH·ªà S·ªê N√ÇNG CAO - LOGISTIC REGRESSION\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 1. L·ªçc d·ªØ li·ªáu OOT t·ª´ b·∫£ng t·ªïng\n",
    "# L∆∞u √Ω: df_score_output l√† b·∫£ng b·∫°n ƒë√£ t·∫°o ·ªü c√°c b∆∞·ªõc tr∆∞·ªõc trong file ipynb\n",
    "df_oot = df_score_output[df_score_output[\"DATA_TYPE\"] == \"OOT\"]\n",
    "df_train = df_score_output[df_score_output[\"DATA_TYPE\"] == \"TRAIN\"]\n",
    "\n",
    "# 2. T√≠nh c√°c ch·ªâ s·ªë hi·ªáu su·∫•t tr√™n OOT\n",
    "if not df_oot.empty:\n",
    "    calculate_advanced_metrics_from_df(df_oot, target_col='y', prob_col='PD', label=\"OOT DATASET\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu OOT!\")\n",
    "\n",
    "# 3. T√≠nh PSI (ƒê·ªô ·ªïn ƒë·ªãnh c·ªßa m√¥ h√¨nh gi·ªØa Train v√† OOT)\n",
    "# D√πng PD ƒë·ªÉ t√≠nh PSI\n",
    "psi_value = calculate_psi_score(df_train[\"PD\"], df_oot[\"PD\"])\n",
    "\n",
    "print(f\">>> STABILITY (PSI - Train vs OOT): {psi_value:.4f}\")\n",
    "if psi_value < 0.1:\n",
    "    print(\"   ‚úÖ PSI < 0.1: M√¥ h√¨nh r·∫•t ·ªïn ƒë·ªãnh.\")\n",
    "elif psi_value < 0.25:\n",
    "    print(\"   ‚ö†Ô∏è PSI 0.1-0.25: M√¥ h√¨nh bi·∫øn ƒë·ªông nh·∫π.\")\n",
    "else:\n",
    "    print(\"   ‚ùå PSI > 0.25: M√¥ h√¨nh kh√¥ng ·ªïn ƒë·ªãnh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e93e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 11 ‚Äî KS STATISTIC (TIM CUT-OFF)\n",
    "# # ============================================================\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from optbinning import OptimalBinning\n",
    "\n",
    "# print(\"\\n[B∆Ø·ªöC 11] T√¨m cut-off b·∫±ng KS...\")\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_train_full, pd_train)\n",
    "# ks_values = tpr - fpr\n",
    "\n",
    "# ks_max = ks_values.max()\n",
    "# ks_cutoff = thresholds[np.argmax(ks_values)]\n",
    "\n",
    "# print(f\" ‚Üí KS max = {ks_max:.4f}\")\n",
    "# print(f\" ‚Üí Cut-off t·ªëi ∆∞u = {ks_cutoff:.4f}\")\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 12 ‚Äî X√ÇY THANG H·∫†NG (OPT BINNING)\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 12] X√¢y thang h·∫°ng b·∫±ng OptBinning...\")\n",
    "\n",
    "# optb = OptimalBinning(\n",
    "#     name=\"RatingScale\",\n",
    "#     dtype=\"numerical\",\n",
    "#     monotonic_trend=\"ascending\",   # PD tƒÉng ‚Üí r·ªßi ro tƒÉng\n",
    "#     max_n_bins=10\n",
    "# )\n",
    "\n",
    "# # Fit tr√™n TRAIN\n",
    "# optb.fit(pd_train, y_train_full)\n",
    "\n",
    "# bin_table = optb.binning_table.build()\n",
    "# print(bin_table)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 13 ‚Äî L·∫§Y CUTPOINTS V√Ä G√ÅN BIN\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 13] √Åp d·ª•ng rating cho to√†n b·ªô dataset...\")\n",
    "\n",
    "# cuts = optb.splits\n",
    "# print(\"Cutpoints:\", cuts)\n",
    "\n",
    "# df_score_output[\"BIN\"] = np.digitize(df_score_output[\"PD\"], cuts, right=True)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 14 ‚Äî G√ÅN 10 H·∫†NG (AAA ‚Üí CC)\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 14] Mapping BIN ‚Üí RATING...\")\n",
    "\n",
    "# bin_mean_pd = df_score_output.groupby(\"BIN\")[\"PD\"].mean().sort_values()\n",
    "\n",
    "\n",
    "# rating_labels = [\"AAA\",\"AA+\",\"AA\",\"AA-\",\"A+\",\"A\",\"A-\",\"BBB\",\"BB\",\"B\"]\n",
    "\n",
    "# sorted_bins = bin_mean_pd.index.tolist()\n",
    "\n",
    "# bin_to_rating = {b: rating_labels[i] for i, b in enumerate(sorted_bins)}\n",
    "\n",
    "# df_score_output[\"RATING\"] = df_score_output[\"BIN\"].map(bin_to_rating)\n",
    "\n",
    "\n",
    "# print(df_score_output[[\"SEGMENT\", \"PD\", \"SCORE\", \"BIN\", \"RATING\"]].head())\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 15 ‚Äî KI·ªÇM TRA ƒê∆†N ƒêI·ªÜU (MONOTONICITY)\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 15] Ki·ªÉm tra t√≠nh ƒë∆°n ƒëi·ªáu c·ªßa PD theo Rating...\")\n",
    "\n",
    "# rating_pd = df_score_output.groupby(\"RATING\")[\"PD\"].mean().reindex(rating_labels)\n",
    "# print(rating_pd)\n",
    "\n",
    "# is_monotonic = rating_pd.is_monotonic_increasing\n",
    "# print(\" ‚Üí PD c√≥ ƒë∆°n ƒëi·ªáu kh√¥ng? ‚Üí\", is_monotonic)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 16 ‚Äî KI·ªÇM TRA S·ª∞ KH√ÅC BI·ªÜT R·ª¶I RO GI·ªÆA C√ÅC H·∫†NG\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 16] Ki·ªÉm tra ƒë·ªô t√°ch b·∫°ch gi·ªØa c√°c rating...\")\n",
    "\n",
    "# rating_diff = rating_pd.diff()\n",
    "# print(rating_diff)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 17 ‚Äî KI·ªÇM TRA M·ª®C ƒê·ªò T·∫¨P TRUNG\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 17] Ki·ªÉm tra m·ª©c ƒë·ªô t·∫≠p trung kh√°ch h√†ng...\")\n",
    "\n",
    "# rating_dist = df_score_output[\"RATING\"].value_counts(normalize=True)\n",
    "# print(rating_dist)\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 18 ‚Äî T√çNH HHI\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 18] T√≠nh Herfindahl-Hirschman Index (HHI)...\")\n",
    "\n",
    "# HHI = np.sum(rating_dist ** 2)\n",
    "# print(f\" ‚Üí HHI = {HHI:.6f}\")\n",
    "\n",
    "# if HHI < 0.10:\n",
    "#     print(\" ‚Üí Ph√¢n b·ªë rating R·∫§T T·ªêT (r·∫•t ƒë·ªÅu).\")\n",
    "# elif HHI < 0.18:\n",
    "#     print(\" ‚Üí Ph√¢n b·ªë rating CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C.\")\n",
    "# else:\n",
    "#     print(\" ‚Üí T·∫≠p trung QU√Å M·ª®C ‚Üí n√™n xem l·∫°i c√°ch binning.\")\n",
    "\n",
    "\n",
    "# # ============================================================\n",
    "# # B∆Ø·ªöC 19 ‚Äî XU·∫§T B·∫¢NG CU·ªêI\n",
    "# # ============================================================\n",
    "# print(\"\\n[B∆Ø·ªöC 19] Xu·∫•t b·∫£ng cu·ªëi c√πng...\")\n",
    "\n",
    "# df_final_rating = df_score_output.copy()\n",
    "# display(df_final_rating.head())\n",
    "    \n",
    "# print(\"‚Üí Ho√†n t·∫•t to√†n b·ªô Rating Pipeline!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "572f12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # B·∫¢NG THANG H·∫†NG CU·ªêI ‚Äî SUMMARY TABLE (THEO KHO·∫¢NG ƒêI·ªÇM)\n",
    "# # ============================================================\n",
    "\n",
    "# print(\"\\n[B·∫¢NG T·ªîNG H·ª¢P THANG H·∫†NG ‚Äî KHO·∫¢NG ƒêI·ªÇM]\")\n",
    "\n",
    "# summary_list = []\n",
    "\n",
    "# for stt, rating in enumerate(rating_labels, start=1):\n",
    "\n",
    "#     df_r = df_score_output[df_score_output[\"RATING\"] == rating]\n",
    "\n",
    "#     if df_r.empty:\n",
    "#         summary_list.append([\n",
    "#             stt,\n",
    "#             rating,\n",
    "#             \"\",\n",
    "#             0,\n",
    "#             0,\n",
    "#             None,\n",
    "#             None\n",
    "#         ])\n",
    "#         continue\n",
    "\n",
    "#     # üîπ KHO·∫¢NG ƒêI·ªÇM (SCORE RANGE)\n",
    "#     score_min = df_r[\"SCORE\"].min()\n",
    "#     score_max = df_r[\"SCORE\"].max()\n",
    "#     score_range = f\"{score_min:.2f} ‚Üí {score_max:.2f}\"\n",
    "\n",
    "#     # S·ªë l∆∞·ª£ng\n",
    "#     count = len(df_r)\n",
    "#     pct = count / len(df_score_output)\n",
    "\n",
    "#     # PD ∆∞·ªõc t√≠nh trung b√¨nh\n",
    "#     pd_est = df_r[\"PD\"].mean()\n",
    "\n",
    "#     # T·ª∑ l·ªá v·ª° n·ª£ th·ª±c t·∫ø\n",
    "#     default_rate = df_r[\"y\"].mean() if \"y\" in df_r.columns else None\n",
    "\n",
    "#     summary_list.append([\n",
    "#         stt,\n",
    "#         rating,\n",
    "#         score_range,\n",
    "#         count,\n",
    "#         pct,\n",
    "#         pd_est,\n",
    "#         default_rate\n",
    "#     ])\n",
    "\n",
    "# # T·∫°o DataFrame\n",
    "# df_rating_summary = pd.DataFrame(summary_list, columns=[\n",
    "#     \"STT\",\n",
    "#     \"H·∫°ng\",\n",
    "#     \"Kho·∫£ng ƒëi·ªÉm (Score)\",\n",
    "#     \"S·ªë l∆∞·ª£ng quan s√°t\",\n",
    "#     \"S·ªë l∆∞·ª£ng quan s√°t (%)\",\n",
    "#     \"PD ∆∞·ªõc t√≠nh trung b√¨nh\",\n",
    "#     \"T·ª∑ l·ªá v·ª° n·ª£ th·ª±c t·∫ø\"\n",
    "# ])\n",
    "\n",
    "# # Format\n",
    "# df_rating_summary[\"S·ªë l∆∞·ª£ng quan s√°t (%)\"] = df_rating_summary[\"S·ªë l∆∞·ª£ng quan s√°t (%)\"].apply(lambda x: f\"{x:.2%}\")\n",
    "# df_rating_summary[\"PD ∆∞·ªõc t√≠nh trung b√¨nh\"] = df_rating_summary[\"PD ∆∞·ªõc t√≠nh trung b√¨nh\"].apply(lambda x: None if pd.isna(x) else round(x, 6))\n",
    "# df_rating_summary[\"T·ª∑ l·ªá v·ª° n·ª£ th·ª±c t·∫ø\"] = df_rating_summary[\"T·ª∑ l·ªá v·ª° n·ª£ th·ª±c t·∫ø\"].apply(lambda x: None if pd.isna(x) else round(x, 6))\n",
    "\n",
    "# display(df_rating_summary)\n",
    "\n",
    "# print(\"\\n‚Üí ƒê√£ d·ª±ng xong b·∫£ng thang h·∫°ng cu·ªëi c√πng (kho·∫£ng ƒëi·ªÉm).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Khoa_luan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
